{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2312cd6eab36427d9506c1e5d1e69e67"
   },
   "source": [
    "# Heart Disease Prediction Hackathon\n",
    "\n",
    "This notebook challenges you to put your knowledge to work to create a classifier that could predict whether a patient has heart disease based on some presented clinical data. We have provided you with the necessary code to load the data and get started. \n",
    "\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "Simply put, the problem is to train a model that could predict whether someone has a heart disease based on some clinical data about the patient.\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "See the [Submission](#Submission) section. Make sure to update the last cell of the notebook to reflect your name, email, and your model's score, as shown in that cell.\n",
    "\n",
    "\n",
    "### Goal Setting\n",
    "\n",
    "Your goal is to improve different sections of this notebook (data wrangling, modeling, etc.) to create a more accurate predictor and submit your notebook. Your model's accuracy will determine your ranking in the challenge - the more accurate, the better. \n",
    "\n",
    "**Overfitting:** Beware of overfitting. The data we will use for testing your model is not included in this notebook, so it will be previously unseen by your model. Therefore, make sure your model is not overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f6aaf5d326d47af8721f325f7912777"
   },
   "source": [
    "## Preparing the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b080bca8-396f-4826-8d51-bfbcbe7d5283"
   },
   "outputs": [],
   "source": [
    "# Importing the basic data science libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# configuring Seaborn plots\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ef2c89d4cc845628b826dac2657c4e5"
   },
   "source": [
    "## Data Collection\n",
    "\n",
    "The First step is to collect the data. Here we are directly loading the data from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/heart+disease). You should visit their website and read more about the dataset.\n",
    "\n",
    "### Notes:\n",
    "1. We directly set the column names based on their description on the website above.\n",
    "2. We are importing the pre-processed version of the data. If you want to challenge yourself you can load the raw data using the following address and experiment with that.\n",
    "    > Raw Data: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/cleveland.data\n",
    "    \n",
    "### Acknowledgement:\n",
    "\n",
    "From the [Dataset description](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/heart-disease.names):\n",
    "\n",
    ">   The authors of the databases have requested:\n",
    ">\n",
    ">      ...that any publications resulting from the use of the data include the \n",
    ">      names of the principal investigator responsible for the data collection\n",
    ">      at each institution.  They would be:\n",
    ">\n",
    ">       1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n",
    ">       2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n",
    ">       3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n",
    ">       4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n",
    ">\t  Robert Detrano, M.D., Ph.D.\n",
    ">\n",
    ">   Thanks in advance for abiding by this request.\n",
    ">\n",
    ">   David Aha\n",
    ">   July 22, 1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d044086921c4240bc106f6fd342ddfb"
   },
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "# Specify column names\n",
    "# Specify that ? denotes missing data, aka NA (or NaN: Not-a-Number)\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data',\n",
    "                names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"issick\"],\n",
    "                na_values = \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5067c4b30944d7c85a290a1acc54d60"
   },
   "outputs": [],
   "source": [
    "# Combine all sick values (1,2,3,4) into a single label (1)\n",
    "df.issick = df.issick.astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92266feebf404551aa09b7dc5a276ff5"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Here you will see some basic exploratory plots to gain insights into the data. You should explore the data more to test your hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1cd3f3a99f540db8333c5969a3ac558"
   },
   "outputs": [],
   "source": [
    "# Checking target column counts\n",
    "df.issick.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c62138176af4894b0385abb3afec970"
   },
   "outputs": [],
   "source": [
    "# Plotting target column counts\n",
    "sns.countplot(x=\"issick\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "323ddf33695047fbb4c16dd60229fa54"
   },
   "outputs": [],
   "source": [
    "# Plotting gender distribution counts\n",
    "# HINT: (Advanced) Note that the data is skewed, this will teach our model bias (bad). You can improve you model by removing the skew from your data. An online search is a good start.\n",
    "sns.countplot(x='sex', data=df)\n",
    "plt.title(\"Sex Count (0 = female, 1= male)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8d74fa8e22748dcb11d5ad7c608c055"
   },
   "outputs": [],
   "source": [
    "# Based on the following plot, age smmes to have some corrolation with heart disease. Let's use that in our model.\n",
    "pd.crosstab(df.age,df.issick).plot(kind=\"bar\",figsize=(20,6))\n",
    "plt.title('Heart Disease Frequency for Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed14b13649b44f36805b715b6f4bc4f2"
   },
   "outputs": [],
   "source": [
    "# Plot Survival vs Sex\n",
    "grid = sns.FacetGrid(df, col='sex')\n",
    "grid.map(sns.countplot, 'issick')\n",
    "\n",
    "# Add Legend\n",
    "grid.add_legend()\n",
    "grid.set_axis_labels(\"is sick\", \"Frequency\")\n",
    "\n",
    "# Add Title\n",
    "grid.fig.subplots_adjust(top=0.8)\n",
    "grid.fig.suptitle('Sex vs. sickness (0 = female, 1= male)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "820b9be2475843dc838aceeb74d27216"
   },
   "outputs": [],
   "source": [
    "# Plot sickness across HearRate and Age\n",
    "\n",
    "fig = sns.scatterplot(data=df, x='age', y='thalach', hue='issick')\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Maximum heart rate\")\n",
    "plt.title(\"sickness across HearRate and Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13b3af4d40d64202b167e118e2be6f69"
   },
   "source": [
    "### Your turn:\n",
    "\n",
    "You can use the following space to explore the data and test your hypotheses. For instance, you might find some skew in the data; that is, you may have significantly more data for one class than the other (e.g., more male samples than female). In that case, you can look into different methods to remove the skew from your data to improve your model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fe7ba3f328a411a83c7304d1a78f5f1"
   },
   "outputs": [],
   "source": [
    "# Your Turn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5595b256d7814d04a93a94f445dc4bd4"
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    "In this section, we will clean our data. Since UCI has already pre-processed this dataset, there is only a little work to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43b9f7ed0b0e44ed8ce7fe8f44efa760"
   },
   "outputs": [],
   "source": [
    "# Let's see which rows have NA values\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25771e8ad10d4335ac25c22c6da8925e"
   },
   "outputs": [],
   "source": [
    "# Now let's fill in the NA values with the mean of each column\n",
    "## Hint: You may want to drop those 4 rows, fill them with df.mean() instead of 0, or fill them in with a more realistic method.\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed01e9c43ef541e18c452c7d060c8723"
   },
   "outputs": [],
   "source": [
    "# Let's verify that they are no rows with NA anymore\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d11d12f4f8d4ca887f9767bd79c5902"
   },
   "source": [
    "### Your Turn:\n",
    "\n",
    "You can use the space below to explore other methods of filling in missing data instead of filling in 0. You'd need to rerun the cells from the top until the point where we fill `NaN` with `mean()` (two cells above) and then do your filling techniques instead. Alternatively, you can try to remove those rows to see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "303d12b6d5f84d38952ad520ac6530d7"
   },
   "outputs": [],
   "source": [
    "# Your turn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f986ef3f5a844a7180656f3227e40b57"
   },
   "source": [
    "## Data Wrangling (Data Engineering)\n",
    "\n",
    "Time to clean up our data. Reading the documentation for this dataset, we notice that `cp`, `thal`, and `slope` are categorical data. We should treat them as such instead of linear numerical values to improve our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdf6b634c5f341b29d6517c0a3eb62bc"
   },
   "outputs": [],
   "source": [
    "# Convert cp, thal, and slope to catogories and replace them with a number \n",
    "df[\"cp\"] = df[\"cp\"].astype('category')\n",
    "df[\"thal\"] = df[\"thal\"].astype('category')\n",
    "df[\"slope\"] = df[\"slope\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b0f4fb1b3ab4b578477ea576907056d"
   },
   "outputs": [],
   "source": [
    "# Let's make sure Pandas is treating cp, thal, and slope as categorical data\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "265aab82ec5b4f088bfbcbaf1aa0fc1f"
   },
   "source": [
    "### Your turn:\n",
    "\n",
    "You can use your domain knowledge about what might indicate heart disease and try to create those columns. For instance, you might want to multiply two columns and save them as a new column, or you might want to do a nonlinear operation (think logarithm or exponentiation) on some columns.  If you think you can find something that may more directly indicate heart disease, try adding that and see how your model's performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e69b189261ec43e1b5d3a78d9cb2edb8"
   },
   "outputs": [],
   "source": [
    "## Your turn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cfc702bf9d1486e8686ce748ff17a7a"
   },
   "source": [
    "## Data Analysis (Model Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73a9f4428a6c462c9eb5de16903d2d6e"
   },
   "outputs": [],
   "source": [
    "# We now separate our input data and prediction label into X and y\n",
    "\n",
    "y = df.issick.values\n",
    "X = df.drop(['issick'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07e945a1ce7c44f0a8db35034181b476"
   },
   "outputs": [],
   "source": [
    "# Let's now normalize (scale so all values are between 0-1) our columns\n",
    "# HINT: This is useful for models such as sklearn.linear_model.LogisticRegression which performs well on this data. You can try that model later in this section.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.normalize(X, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26ed187076ae4075a82380fa8af95608"
   },
   "outputs": [],
   "source": [
    "# Let's separate our data for training and testing (here test and validation are the same.)\n",
    "# HINT: you may want to try to keep a smaller part of the data for testing. 50/50 may be too little for training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.85,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f78c20265aa54043a1c8a22df18170de"
   },
   "outputs": [],
   "source": [
    "# Time to train our models and test them. \n",
    "# Let's start with a Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "acc = dtc.score(X_test, y_test)*100\n",
    "print(\"Decision Tree Test Accuracy {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfda691fe09e476d9ff7437147965c02"
   },
   "outputs": [],
   "source": [
    "# Let's also try a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "acc = rf.score(X_test,y_test)*100\n",
    "print(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec841c28855b443c95ccce683f01415e"
   },
   "source": [
    "### Your Turn:\n",
    "\n",
    "You may want to try the following models as well:\n",
    "- SVC: [Support Vector Machine Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- LR: [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c027eda2b2bf44058df78d2f0d569b1d"
   },
   "outputs": [],
   "source": [
    "# Your Turn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61db2c65930343298713be0dded21d6a"
   },
   "source": [
    "## Going Further:\n",
    "\n",
    "We explored some of the essential data cleaning and modeling techniques above. To go further, look at the hints that we embedded throughout this notebook. \n",
    "\n",
    "Additionally, since this is a well-studied dataset, you can look online for other public work that might inspire you. This [Kaggle forum](https://www.kaggle.com/ronitf/heart-disease-uci/code) is a good place to get started. For instance, [this notebook](https://www.kaggle.com/faressayah/predicting-heart-disease-using-machine-learning) might be a good read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4af18674707429b8fed37e57002eee5"
   },
   "outputs": [],
   "source": [
    "## Your turn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c17db894dbdb4db68a190b52f8aa83dc"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Include your final model's score in the cell below and submit your notebook as follows:\n",
    "\n",
    "1. Update the cell below: Include `name`, `email`, and final model score\n",
    "1. Save Notebook: `File` > `Save`\n",
    "1. Download Notebook: `File` > `Download As` > `Notebook`\n",
    "1. Upload your notebook here: https://ibm.biz/kp-hack-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70d84053c50a48fb99981224db0faff9"
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "# Name: \n",
    "# Email Address: \n",
    "\n",
    "\n",
    "## REPLACE THIS SECTION ########################## \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "acc = dtc.score(X_test, y_test)*100\n",
    "## REPLACE ABO ####################################\n",
    "\n",
    "print(\"Decision Tree Test Accuracy {:.2f}%\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}